{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/debian/Vojta/project.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(mmread(\u001b[39m'\u001b[39;49m\u001b[39mdata/E-MTAB-10290.aggregated_filtered_normalised_counts.mtx\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mtodense())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df\n",
      "File \u001b[0;32m~/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/scipy/io/_mmio.py:129\u001b[0m, in \u001b[0;36mmmread\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmmread\u001b[39m(source):\n\u001b[1;32m     85\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m    Reads the contents of a Matrix Market file-like 'source' into a matrix.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m           [0., 0., 0., 0., 0.]])\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m MMFile()\u001b[39m.\u001b[39;49mread(source)\n",
      "File \u001b[0;32m~/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/scipy/io/_mmio.py:579\u001b[0m, in \u001b[0;36mMMFile.read\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    578\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_header(stream)\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_body(stream)\n\u001b[1;32m    581\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m close_it:\n",
      "File \u001b[0;32m~/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/scipy/io/_mmio.py:770\u001b[0m, in \u001b[0;36mMMFile._parse_body\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    767\u001b[0m     V \u001b[39m=\u001b[39m zeros(entries, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    769\u001b[0m entry_number \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 770\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m stream:\n\u001b[1;32m    771\u001b[0m     \u001b[39m# line.startswith('%')\u001b[39;00m\n\u001b[1;32m    772\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line \u001b[39mor\u001b[39;00m line[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m37\u001b[39m] \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mstrip():\n\u001b[1;32m    773\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(mmread('data/E-MTAB-10290.aggregated_filtered_normalised_counts.mtx').todense())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>ENSG00000001460</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000289565</th>\n",
       "      <th>ENSG00000289604</th>\n",
       "      <th>ENSG00000289685</th>\n",
       "      <th>ENSG00000289690</th>\n",
       "      <th>ENSG00000289694</th>\n",
       "      <th>ENSG00000289695</th>\n",
       "      <th>ENSG00000289697</th>\n",
       "      <th>ENSG00000289700</th>\n",
       "      <th>ENSG00000289701</th>\n",
       "      <th>ENSG00000289716</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SAMEA8461660-AAACCCAAGGTTCAGG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.567640</td>\n",
       "      <td>76.132470</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.755005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.066235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>152.264940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA8461660-AAACCCAAGGTTTACC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.5034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.391530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.006800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.755100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.251700</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA8461660-AAACCCAGTAGCTGAG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.331635</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.331635</td>\n",
       "      <td>0.822164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.165817</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA8461660-AAACCCAGTCAGATTC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>147.972780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>221.959170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.972780</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA8461660-AAACCCAGTGCGAACA</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.385530</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.596382</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA8461667-TTTGGTTCACTTGACA</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.591175</td>\n",
       "      <td>135.446290</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.574383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA8461667-TTTGGTTTCCCATGGG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>191.640100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.172240</td>\n",
       "      <td>76.086120</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.086120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.129180</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA8461667-TTTGTTGAGATCCAAA</th>\n",
       "      <td>129.39122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.347805</td>\n",
       "      <td>129.391220</td>\n",
       "      <td>110.22637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>226.434630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.347805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.69561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA8461667-TTTGTTGCAGCCGTCA</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>57.774826</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.143150</td>\n",
       "      <td>251.584960</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.996223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.316994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA8461667-TTTGTTGGTTTACTGG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>184.615390</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>41.025660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.153850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.307690</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29203 rows Ã— 25511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ENSG00000000003  ENSG00000000419  \\\n",
       "SAMEA8461660-AAACCCAAGGTTCAGG          0.00000         0.000000   \n",
       "SAMEA8461660-AAACCCAAGGTTTACC          0.00000         0.000000   \n",
       "SAMEA8461660-AAACCCAGTAGCTGAG          0.00000         0.000000   \n",
       "SAMEA8461660-AAACCCAGTCAGATTC          0.00000         0.000000   \n",
       "SAMEA8461660-AAACCCAGTGCGAACA          0.00000         0.000000   \n",
       "...                                        ...              ...   \n",
       "SAMEA8461667-TTTGGTTCACTTGACA          0.00000         0.000000   \n",
       "SAMEA8461667-TTTGGTTTCCCATGGG          0.00000       191.640100   \n",
       "SAMEA8461667-TTTGTTGAGATCCAAA        129.39122         0.000000   \n",
       "SAMEA8461667-TTTGTTGCAGCCGTCA          0.00000        57.774826   \n",
       "SAMEA8461667-TTTGTTGGTTTACTGG          0.00000         0.000000   \n",
       "\n",
       "                               ENSG00000000457  ENSG00000000460  \\\n",
       "SAMEA8461660-AAACCCAAGGTTCAGG           0.0000              0.0   \n",
       "SAMEA8461660-AAACCCAAGGTTTACC          88.5034              0.0   \n",
       "SAMEA8461660-AAACCCAGTAGCTGAG           0.0000              0.0   \n",
       "SAMEA8461660-AAACCCAGTCAGATTC           0.0000              0.0   \n",
       "SAMEA8461660-AAACCCAGTGCGAACA           0.0000              0.0   \n",
       "...                                        ...              ...   \n",
       "SAMEA8461667-TTTGGTTCACTTGACA           0.0000              0.0   \n",
       "SAMEA8461667-TTTGGTTTCCCATGGG           0.0000              0.0   \n",
       "SAMEA8461667-TTTGTTGAGATCCAAA           0.0000              0.0   \n",
       "SAMEA8461667-TTTGTTGCAGCCGTCA           0.0000              0.0   \n",
       "SAMEA8461667-TTTGTTGGTTTACTGG           0.0000              0.0   \n",
       "\n",
       "                               ENSG00000000938  ENSG00000000971  \\\n",
       "SAMEA8461660-AAACCCAAGGTTCAGG              0.0       111.567640   \n",
       "SAMEA8461660-AAACCCAAGGTTTACC              0.0       102.391530   \n",
       "SAMEA8461660-AAACCCAGTAGCTGAG              0.0         0.000000   \n",
       "SAMEA8461660-AAACCCAGTCAGATTC              0.0         0.000074   \n",
       "SAMEA8461660-AAACCCAGTGCGAACA              0.0         0.000000   \n",
       "...                                        ...              ...   \n",
       "SAMEA8461667-TTTGGTTCACTTGACA              0.0        54.591175   \n",
       "SAMEA8461667-TTTGGTTTCCCATGGG              0.0       152.172240   \n",
       "SAMEA8461667-TTTGTTGAGATCCAAA              0.0        32.347805   \n",
       "SAMEA8461667-TTTGTTGCAGCCGTCA              0.0        69.143150   \n",
       "SAMEA8461667-TTTGTTGGTTTACTGG              0.0         0.000000   \n",
       "\n",
       "                               ENSG00000001036  ENSG00000001084  \\\n",
       "SAMEA8461660-AAACCCAAGGTTCAGG        76.132470          0.00000   \n",
       "SAMEA8461660-AAACCCAAGGTTTACC         0.000000          0.00000   \n",
       "SAMEA8461660-AAACCCAGTAGCTGAG        82.331635          0.00000   \n",
       "SAMEA8461660-AAACCCAGTCAGATTC         0.000000          0.00000   \n",
       "SAMEA8461660-AAACCCAGTGCGAACA       190.385530          0.00000   \n",
       "...                                        ...              ...   \n",
       "SAMEA8461667-TTTGGTTCACTTGACA       135.446290          0.00000   \n",
       "SAMEA8461667-TTTGGTTTCCCATGGG        76.086120          0.00000   \n",
       "SAMEA8461667-TTTGTTGAGATCCAAA       129.391220        110.22637   \n",
       "SAMEA8461667-TTTGTTGCAGCCGTCA       251.584960          0.00000   \n",
       "SAMEA8461667-TTTGTTGGTTTACTGG       184.615390          0.00000   \n",
       "\n",
       "                               ENSG00000001167  ENSG00000001460  ...  \\\n",
       "SAMEA8461660-AAACCCAAGGTTCAGG              0.0         0.000000  ...   \n",
       "SAMEA8461660-AAACCCAAGGTTTACC              0.0         0.000000  ...   \n",
       "SAMEA8461660-AAACCCAGTAGCTGAG              0.0         0.000000  ...   \n",
       "SAMEA8461660-AAACCCAGTCAGATTC              0.0         0.000000  ...   \n",
       "SAMEA8461660-AAACCCAGTGCGAACA              0.0         0.000000  ...   \n",
       "...                                        ...              ...  ...   \n",
       "SAMEA8461667-TTTGGTTCACTTGACA              0.0         0.000000  ...   \n",
       "SAMEA8461667-TTTGGTTTCCCATGGG              0.0         0.000000  ...   \n",
       "SAMEA8461667-TTTGTTGAGATCCAAA              0.0         0.000000  ...   \n",
       "SAMEA8461667-TTTGTTGCAGCCGTCA              0.0        56.996223  ...   \n",
       "SAMEA8461667-TTTGTTGGTTTACTGG              0.0         0.000000  ...   \n",
       "\n",
       "                               ENSG00000289565  ENSG00000289604  \\\n",
       "SAMEA8461660-AAACCCAAGGTTCAGG        50.755005              0.0   \n",
       "SAMEA8461660-AAACCCAAGGTTTACC         0.000000              0.0   \n",
       "SAMEA8461660-AAACCCAGTAGCTGAG         0.000000              0.0   \n",
       "SAMEA8461660-AAACCCAGTCAGATTC       147.972780              0.0   \n",
       "SAMEA8461660-AAACCCAGTGCGAACA         0.000000              0.0   \n",
       "...                                        ...              ...   \n",
       "SAMEA8461667-TTTGGTTCACTTGACA         0.000000              0.0   \n",
       "SAMEA8461667-TTTGGTTTCCCATGGG         0.000000              0.0   \n",
       "SAMEA8461667-TTTGTTGAGATCCAAA         0.000000              0.0   \n",
       "SAMEA8461667-TTTGTTGCAGCCGTCA         0.000000              0.0   \n",
       "SAMEA8461667-TTTGTTGGTTTACTGG        41.025660              0.0   \n",
       "\n",
       "                               ENSG00000289685  ENSG00000289690  \\\n",
       "SAMEA8461660-AAACCCAAGGTTCAGG        38.066235         0.000000   \n",
       "SAMEA8461660-AAACCCAAGGTTTACC       177.006800         0.000000   \n",
       "SAMEA8461660-AAACCCAGTAGCTGAG         0.000000        82.331635   \n",
       "SAMEA8461660-AAACCCAGTCAGATTC         0.000000         0.000000   \n",
       "SAMEA8461660-AAACCCAGTGCGAACA         0.000000         0.000000   \n",
       "...                                        ...              ...   \n",
       "SAMEA8461667-TTTGGTTCACTTGACA        22.574383         0.000000   \n",
       "SAMEA8461667-TTTGGTTTCCCATGGG        76.086120         0.000000   \n",
       "SAMEA8461667-TTTGTTGAGATCCAAA         0.000000         0.000000   \n",
       "SAMEA8461667-TTTGTTGCAGCCGTCA        50.316994         0.000000   \n",
       "SAMEA8461667-TTTGTTGGTTTACTGG         0.000000         0.000000   \n",
       "\n",
       "                               ENSG00000289694  ENSG00000289695  \\\n",
       "SAMEA8461660-AAACCCAAGGTTCAGG       152.264940              0.0   \n",
       "SAMEA8461660-AAACCCAAGGTTTACC       132.755100              0.0   \n",
       "SAMEA8461660-AAACCCAGTAGCTGAG         0.822164              0.0   \n",
       "SAMEA8461660-AAACCCAGTCAGATTC       221.959170              0.0   \n",
       "SAMEA8461660-AAACCCAGTGCGAACA         0.000000              0.0   \n",
       "...                                        ...              ...   \n",
       "SAMEA8461667-TTTGGTTCACTTGACA         0.000000              0.0   \n",
       "SAMEA8461667-TTTGGTTTCCCATGGG         0.000000              0.0   \n",
       "SAMEA8461667-TTTGTTGAGATCCAAA       226.434630              0.0   \n",
       "SAMEA8461667-TTTGTTGCAGCCGTCA         0.000000              0.0   \n",
       "SAMEA8461667-TTTGTTGGTTTACTGG       246.153850              0.0   \n",
       "\n",
       "                               ENSG00000289697  ENSG00000289700  \\\n",
       "SAMEA8461660-AAACCCAAGGTTCAGG         0.000000              0.0   \n",
       "SAMEA8461660-AAACCCAAGGTTTACC         0.000000              0.0   \n",
       "SAMEA8461660-AAACCCAGTAGCTGAG         0.000000              0.0   \n",
       "SAMEA8461660-AAACCCAGTCAGATTC         0.000000              0.0   \n",
       "SAMEA8461660-AAACCCAGTGCGAACA         0.000000              0.0   \n",
       "...                                        ...              ...   \n",
       "SAMEA8461667-TTTGGTTCACTTGACA         0.000000              0.0   \n",
       "SAMEA8461667-TTTGGTTTCCCATGGG         0.000000              0.0   \n",
       "SAMEA8461667-TTTGTTGAGATCCAAA        32.347805              0.0   \n",
       "SAMEA8461667-TTTGTTGCAGCCGTCA         0.000000              0.0   \n",
       "SAMEA8461667-TTTGTTGGTTTACTGG         0.000000              0.0   \n",
       "\n",
       "                               ENSG00000289701  ENSG00000289716  \n",
       "SAMEA8461660-AAACCCAAGGTTCAGG         0.000000          0.00000  \n",
       "SAMEA8461660-AAACCCAAGGTTTACC        44.251700          0.00000  \n",
       "SAMEA8461660-AAACCCAGTAGCTGAG        41.165817          0.00000  \n",
       "SAMEA8461660-AAACCCAGTCAGATTC       147.972780          0.00000  \n",
       "SAMEA8461660-AAACCCAGTGCGAACA        47.596382          0.00000  \n",
       "...                                        ...              ...  \n",
       "SAMEA8461667-TTTGGTTCACTTGACA         0.000000          0.00000  \n",
       "SAMEA8461667-TTTGGTTTCCCATGGG       114.129180          0.00000  \n",
       "SAMEA8461667-TTTGTTGAGATCCAAA         0.000000         64.69561  \n",
       "SAMEA8461667-TTTGTTGCAGCCGTCA         0.000000          0.00000  \n",
       "SAMEA8461667-TTTGTTGGTTTACTGG        92.307690          0.00000  \n",
       "\n",
       "[29203 rows x 25511 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the gene names from file and add them as row names\n",
    "with open('data/E-MTAB-10290.aggregated_filtered_normalised_counts.mtx_rows') as f:\n",
    "    gene_names = [i.split()[0] for i in f.read().splitlines()]\n",
    "df.index = gene_names\n",
    "\n",
    "# read the cell names from file and add them as column names\n",
    "with open('data/E-MTAB-10290.aggregated_filtered_normalised_counts.mtx_cols') as f:\n",
    "    cell_names = f.read().splitlines()\n",
    "df.columns = cell_names\n",
    "\n",
    "# transpose the dataframe so that the genes are the columns and the cells are the rows\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal', 'normal', 'normal', ..., 'cutaneous melanoma',\n",
       "       'cutaneous melanoma', 'cutaneous melanoma'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the experimental design from tsv file\n",
    "design = pd.read_csv('data/ExpDesign-E-MTAB-10290.tsv', sep='\\t')\n",
    "\n",
    "# keep only the columns we need\n",
    "design = design[['Assay', 'Sample Characteristic[disease]']]\n",
    "design.columns = ['cell', 'disease']\n",
    "\n",
    "design.set_index('cell', inplace=True)\n",
    "\n",
    "design = np.ndarray.flatten(design.values)\n",
    "design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.tocsr()\n",
    "\n",
    "# get sample of 1000 cells and 1000 genes\n",
    "#df = df[np.random.choice(df.shape[0], 1000, replace=False), :]\n",
    "#df = df[:, np.random.choice(df.shape[1], 1000, replace=False)]\n",
    "\n",
    "\n",
    "# get 1000 cells from the design\n",
    "#design = design[np.random.choice(design.shape[0], 1000, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f54ec4ebf70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# set the seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, design, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['cutaneous melanoma', 'normal'], dtype=object), array([2418, 3423]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cutaneous melanoma', 'normal'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the target labels into integers\n",
    "le = LabelEncoder()\n",
    "#y_train = le.fit_transform(y_train.values.ravel())\n",
    "#y_test = le.transform(y_test.values.ravel())\n",
    "y_train = le.fit_transform(y_train.ravel())\n",
    "y_test = le.transform(y_test.ravel())\n",
    "\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into PyTorch tensors\n",
    "#X_train = torch.from_numpy(X_train.todense()).to_sparse()\n",
    "#X_train = X_train.tocoo()\n",
    "#X_train = torch.sparse.LongTensor(torch.LongTensor([X_train.row.tolist(), X_train.col.tolist()]),torch.FloatTensor(X_train.data))\n",
    "#X_test = torch.from_numpy(X_test.todense()).to_sparse()\n",
    "#X_test = X_test.tocoo()\n",
    "#X_test = torch.sparse.LongTensor(torch.LongTensor([X_test.row.tolist(), X_test.col.tolist()]),torch.FloatTensor(X_test.data))\n",
    "\n",
    "X_train = torch.from_numpy(X_train.values).float().to(device)\n",
    "X_test = torch.from_numpy(X_test.values).float().to(device)\n",
    "\n",
    "# convert the target labels into torch tensors\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train)).long().to(device)\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test)).long().to(device)\n",
    "\n",
    "# create Tensor datasets\n",
    "train_ds = data_utils.TensorDataset(X_train, y_train)\n",
    "test_ds = data_utils.TensorDataset(X_test, y_test)\n",
    "\n",
    "# define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# load the data\n",
    "train_dl = data_utils.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = data_utils.DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(25511, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 2000)\n",
    "        self.fc3 = nn.Linear(2000, 1000)\n",
    "        self.fc4 = nn.Linear(1000, 100)\n",
    "        self.fc5 = nn.Linear(100, 2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        #x = self.dropout(x)\n",
    "        return self.fc5(x)\n",
    "    \n",
    "# initialize the model\n",
    "model = Net()\n",
    "\n",
    "# define the optimizer and the loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define the training function\n",
    "def train(model, train_dl, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i, (X_batch, y_batch) in enumerate(train_dl):\n",
    "        #if i % 100 == 0:\n",
    "            #print(i)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch.to(device))\n",
    "        loss = criterion(y_pred, y_batch.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_dl)\n",
    "    return model, train_loss\n",
    "\n",
    "# define the testing function\n",
    "def test(model, test_dl, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct, total = 0, 0\n",
    "    predictions, truth = [], []\n",
    "    with torch.no_grad():\n",
    "        for i, (X_batch, y_batch) in enumerate(test_dl):\n",
    "            #if i % 100 == 0:\n",
    "                #print(i)\n",
    "            y_pred = model(X_batch.to(device))\n",
    "            loss = criterion(y_pred, y_batch.to(device))\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            #if i == 0:\n",
    "                #print(y_pred)\n",
    "                #print(predicted)\n",
    "                #print(y_batch)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            truth.extend(y_batch.cpu().numpy())\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    val_loss = running_loss / len(test_dl)\n",
    "    return val_loss, correct / total, predictions, truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=25511, out_features=5000, bias=True)\n",
       "  (fc2): Linear(in_features=5000, out_features=2000, bias=True)\n",
       "  (fc3): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "  (fc4): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (fc5): Linear(in_features=100, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send the model to the device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 3.183 | Val Loss: 0.002 | Val Acc: 1.00 |\n",
      "| Epoch: 02 | Train Loss: 0.394 | Val Loss: 0.679 | Val Acc: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.690 | Val Loss: 0.678 | Val Acc: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.681 | Val Loss: 0.678 | Val Acc: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.699 | Val Loss: 0.678 | Val Acc: 0.59 |\n"
     ]
    }
   ],
   "source": [
    "# train the model for 100 epochs\n",
    "epochs = 5\n",
    "train_losses, val_losses, val_accs = [], [], []\n",
    "for epoch in range(epochs):\n",
    "    model, train_loss = train(model, train_dl, optimizer, criterion)\n",
    "    val_loss, val_acc, _, _ = test(model, test_dl, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.2f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training and validation losses\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the validation accuracy\n",
    "plt.plot(val_accs, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debian/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/debian/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/debian/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2418\n",
      "           1       0.59      1.00      0.74      3423\n",
      "\n",
      "    accuracy                           0.59      5841\n",
      "   macro avg       0.29      0.50      0.37      5841\n",
      "weighted avg       0.34      0.59      0.43      5841\n",
      "\n",
      "[[   0 2418]\n",
      " [   0 3423]]\n",
      "0.5860297894196199\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "_, _, predictions, truth = test(model, test_dl, criterion)\n",
    "print(classification_report(truth, predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "cm = confusion_matrix(truth, predictions)\n",
    "print(cm)\n",
    "\n",
    "# print the accuracy score\n",
    "print(accuracy_score(truth, predictions))\n",
    "\n",
    "# save the model\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/debian/Vojta/project.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m predictions\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# predict the labels for the test set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m predictions \u001b[39m=\u001b[39m predict(model, test_dl)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m predictions \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39minverse_transform(predictions)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m predictions\n",
      "\u001b[1;32m/home/debian/Vojta/project.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (X_batch, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_dl):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         y_pred \u001b[39m=\u001b[39m model(X_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(y_pred\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m         predictions\u001b[39m.\u001b[39mextend(predicted\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/debian/Vojta/project.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m#x = self.dropout(x)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B78.128.251.48/home/debian/Vojta/project.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n",
      "File \u001b[0;32m~/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/MVI_Vojta2/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "\n",
    "# define the prediction function\n",
    "def predict(model, test_dl):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i, (X_batch, _) in enumerate(test_dl):\n",
    "            y_pred = model(X_batch)\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            predictions.extend(predicted.numpy())\n",
    "    return predictions\n",
    "\n",
    "# predict the labels for the test set\n",
    "predictions = predict(model, test_dl)\n",
    "predictions = le.inverse_transform(predictions)\n",
    "predictions\n",
    "\n",
    "# print the cell names and the predicted labels\n",
    "print('cell\\tpredicted label')\n",
    "for cell, prediction in zip(cell_names, predictions):\n",
    "    print(f'{cell}\\t{prediction}')\n",
    "\n",
    "# print the cell names and the true labels\n",
    "print('cell\\ttrue label')\n",
    "for cell, truth in zip(cell_names, df['disease']):\n",
    "    print(f'{cell}\\t{truth}')\n",
    "\n",
    "# print the cell names and the predicted and true labels\n",
    "print('cell\\tpredicted label\\ttrue label')\n",
    "for cell, prediction, truth in zip(cell_names, predictions, df['disease']):\n",
    "    print(f'{cell}\\t{prediction}\\t{truth}')\n",
    "\n",
    "# print the cell names and the predicted and true labels for the cells that were misclassified\n",
    "print('cell\\tpredicted label\\ttrue label')\n",
    "for cell, prediction, truth in zip(cell_names, predictions, df['disease']):\n",
    "    if prediction != truth:\n",
    "        print(f'{cell}\\t{prediction}\\t{truth}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
